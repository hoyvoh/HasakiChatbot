{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from utils import AWANLLM_API_KEY, MODEL\n",
    "\n",
    "\n",
    "url = \"https://api.awanllm.com/v1/chat/completions\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"model\": MODEL,\n",
    "  \"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi!, how can I help you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you write me Haiku about Hare and Tortoise\"}\n",
    "  ],\n",
    "  \"repetition_penalty\": 1.1,\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 0.9,\n",
    "  \"top_k\": 40,\n",
    "  \"max_tokens\": 1024,\n",
    "  \"stream\": True\n",
    "})\n",
    "headers = {\n",
    "  'Content-Type': 'application/json',\n",
    "  'Authorization': f\"Bearer {AWANLLM_API_KEY}\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full response: Here is a haiku:\n",
      "\n",
      "Slow and steady wins\n",
      "Tortoise smiles as hare sleeps on\n",
      "Patience is key\n"
     ]
    }
   ],
   "source": [
    "# Collect the streamed response into a full sentence\n",
    "\n",
    "full_response = \"\"\n",
    "\n",
    "# Iterate through the streaming data\n",
    "for line in response.iter_lines():\n",
    "    if line:  # Avoid processing empty lines\n",
    "        decoded_line = line.decode('utf-8').strip()  # Strip leading/trailing spaces\n",
    "        \n",
    "        if decoded_line == \"data: [DONE]\":\n",
    "            break\n",
    "        \n",
    "        if decoded_line.startswith(\"data: \"):\n",
    "            try:\n",
    "                # Extract the JSON part after 'data:'\n",
    "                json_data = json.loads(decoded_line.split(\"data: \")[1])\n",
    "                # Accumulate the text parts from the response\n",
    "                full_response += json_data[\"choices\"][0][\"delta\"]['content']\n",
    "            except (IndexError, json.JSONDecodeError) as e:\n",
    "                # Print the problematic line for debugging\n",
    "                print(f\"Error decoding JSON from line: {decoded_line}\")\n",
    "                print(f\"Exception: {e}\")\n",
    "\n",
    "print(\"Full response:\", full_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing `get_json_from_prompt` ===\n",
      "JSON Response: {\n",
      "  \"signal\": \"5\",\n",
      "  \"budget\": \"200000\",\n",
      "  \"product_term\": \"son môi, phấn nền, phấn mắt\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI \n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import prompt_design\n",
    "from openai_api import OpenAIClient\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL = os.getenv(\"OPENAI_MODEL\")\n",
    "\n",
    "\n",
    "openai = OpenAIClient()\n",
    "system_prompt = prompt_design.PROMPT_TEMPLATE\n",
    "\n",
    "# user_messages = [\n",
    "#     'Giới thiệu cho tôi các sản phẩm bán chạy nhất.',\n",
    "#     'Ở đây có bán gì rẻ rẻ không?',\n",
    "#     'Cây son mắc nhất trên hasaki là cây nào?'\n",
    "# ]\n",
    "\n",
    "# for message in user_messages:\n",
    "#     response = client.get_response(user_message=message, prompt=system_prompt)\n",
    "#     print(f\"User: {message}\\nAssistant: {response}\")\n",
    " \n",
    "# Test `get_json_from_prompt`\n",
    "print(\"\\n=== Testing `get_json_from_prompt` ===\")\n",
    "guide = '''\n",
    "    Phân tích yêu cầu người dùng theo nhu cầu sau và trả kết quả tương ứng như mô tả. Không thêm bớt hay tự chế ra kết quả.\n",
    "    thay thế cụm có dấu <>, không kèm dấu này, câu trả lời theo dạng json format.\n",
    "    (0) Nếu người dùng chỉ hỏi một câu chào hỏi lịch sự bình thường, hãy trả lại với cú pháp: {'signal':'0', 'query':'<câu hỏi>'}\n",
    "    (1) Nếu người dùng nhắc đến việc tìm hiểu một sản phẩm rất cụ thể, hãy trả lời với cú pháp: {'signal':'1','product_term':'<tên sản phẩm>'}\n",
    "    (2) Nếu người dùng nhắc đến việc so sánh hai sản phẩm rất cụ thể, hãy trả lời với cú pháp: {'signal':'2','product_term_1'='<thông tin sản phẩm 1>','product_term_2'='<thông tin sản phẩm 2>'}\n",
    "    (3) Nếu người dùng nhắc đến việc tìm sản phẩm theo yêu cầu:\n",
    "        hãy trả về các thuộc tính có trong cú pháp sau (nếu có), trong đó signal và product_term là bắt buộc: {'signal':'3','product_term':'<thông tin sản phẩm>', 'product_ingredients': '<thành phần sản phẩm>','price':'<price>', 'operator_price':'<operator>', 'rating':'<rating>', 'operator_rating':'<operator>', 'others':'<thông tin khác>'}\n",
    "        Lưu ý <operator> sẽ là các operator trong mongodb như '$gte', '$lte' khi câu hỏi liên quan đến giá lớn hơn, bé hơn bao nhiêu đó. Hoặc rating cao hơn hay thấp hơn bao nhiêu đó.\n",
    "        Và <price> phải được chuyển về theo dạng ví dụ 10k là 10000.\n",
    "    (4) Nếu người dùng cần hỗ trợ về các chính sách mua hàng, giao hàng, đổi trả, hỗ trợ kỹ thuật, hãy trả lời với cú pháp: {'signal':'4','query':'<query>'}\n",
    "    (5) Nếu người dùng cung cấp một số tiền và cần hỗ trợ mua hàng dựa trên số tiền hiện có, hãy trả lời với cú pháp: \n",
    "    {'signal':'5','budget':'<budget>','product_term':'<Danh sách các term về sản phẩm>'}; \n",
    "    chú ý, budget phải là một con số hoặc một string có thể chuyển thành int một cách trực tiếp.\n",
    "    product term ở đây là một danh sách các sản phẩm gồm sản phẩm đầu là sản phẩm chính và các sản phẩm sau là sản phẩm mà người dùng có thể cũng mua chung được cách nhau bởi dấu phẩy\n",
    "    \n",
    "    Nếu yêu cầu không cụ thể về sản phẩm nào, trả lại theo cú pháp: {'signal':'3','product_term':'<mô tả sản phẩm>','others':'<thông tin khác>'}\n",
    "\n",
    "    '''\n",
    "\n",
    "completion = openai.client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages= [\n",
    "        { 'role': \"system\", 'content':guide },\n",
    "        {'role': \"user\", 'content': \"gợi ý cho tôi sản phẩm trang điểm dưới 200k\"}\n",
    "        ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "# response.choices[0].message\n",
    "assistant_response = completion.choices[0].message.content\n",
    "print(\"JSON Response:\", assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
